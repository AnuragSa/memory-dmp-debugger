# OpenAI Configuration
#OPENAI_API_KEY=your-openai-api-key-here
#OPENAI_MODEL=gpt-4-turbo-preview

# Anthropic Configuration (alternative)
# ANTHROPIC_API_KEY=your-anthropic-api-key-here
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Azure Configuration - works for both Azure OpenAI and Azure AI Foundry

AZURE_OPENAI_API_KEY=[YOUR_AZURE_OPENAI_API_KEY_HERE]
AZURE_OPENAI_ENDPOINT=[YOUR_AZURE_OPENAI_ENDPOINT_HERE]
AZURE_OPENAI_DEPLOYMENT=[YOUR_AZURE_OPENAI_DEPLOYMENT_HERE]
AZURE_OPENAI_API_VERSION=[YOUR_AZURE_OPENAI_API_VERSION_HERE]

# LLM Provider (openai, anthropic, azure)
LLM_PROVIDER=azure

# WinDbg/CDB Configuration
CDB_PATH=C:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\cdb.exe
WINDBG_PATH=C:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\windbg.exe

# Symbol Server Configuration
# Format: SRV*local_cache_dir*https://symbol_server
# The cache directory will be created automatically if it doesn't exist
SYMBOL_PATH=SRV*c:\\symbols*https://msdl.microsoft.com/download/symbols

# Debugger Command Timeout (in seconds)
# Increase for slow commands like !dumpheap, ~*e !CLRStack on large dumps
COMMAND_TIMEOUT=600

# SOS Extension Configuration (optional)
# Specify custom SOS.dll path if analyzing dumps from different .NET runtime versions
# Leave commented to auto-detect SOS from the dump's runtime
# Example for .NET 6.0: C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App\\6.0.x\\sos.dll
# Example for .NET Framework 4.8: C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\sos.dll
#SOS_DLL_PATH=C:\\path\\to\\sos.dll

# DAC (Data Access Component) Configuration (optional but CRITICAL)
# Specify custom mscordacwks.dll path for exact runtime version matching
# MUST match the EXACT build version of .NET runtime in the dump
# Leave commented to auto-download from symbol server (recommended)
# Example for .NET 6.0: C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App\\6.0.25\\mscordacwks.dll
# Example for .NET Core 3.1: C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App\\3.1.32\\mscordaccore.dll
# Example for .NET Framework 4.8: C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\mscordacwks.dll
#MSCORDACWKS_PATH=C:\\path\\to\\mscordacwks.dll

# Logging
LOG_LEVEL=INFO


# Data model commands (set to false to force classic commands only)
ENABLE_DATA_MODEL_COMMANDS=true

# Workflow Configuration
# LangGraph recursion limit - max workflow iterations (each chat question counts as 1)
# Increase if you plan to ask many follow-up questions in interactive mode
GRAPH_RECURSION_LIMIT=200

# Evidence Management & Semantic Search
# Use embeddings for semantic search in interactive mode (requires Azure OpenAI or OpenAI)
USE_EMBEDDINGS=true

# Embeddings Provider (openai or azure)
EMBEDDINGS_PROVIDER=azure

# Azure OpenAI Embeddings Configuration (if EMBEDDINGS_PROVIDER=azure)
# Use separate deployment for embeddings or reuse main endpoint
AZURE_EMBEDDINGS_DEPLOYMENT=text-embedding-3-small
# Optional: use different endpoint for embeddings (defaults to AZURE_OPENAI_ENDPOINT)
#AZURE_EMBEDDINGS_ENDPOINT=https://your-instance.openai.azure.com/
# Optional: use different API key for embeddings (defaults to AZURE_OPENAI_API_KEY)
#AZURE_EMBEDDINGS_API_KEY=your-embeddings-key

# OpenAI Embeddings Configuration (if EMBEDDINGS_PROVIDER=openai)
#EMBEDDINGS_MODEL=text-embedding-3-small

# Storage thresholds
EVIDENCE_STORAGE_THRESHOLD=250000  # Store outputs larger than 250KB externally (optimized for Claude 4.5)
EVIDENCE_CHUNK_SIZE=250000         # Chunk size for LLM analysis (250KB for Claude Sonnet 4.5)
CHUNK_ANALYSIS_DELAY=2.0           # Delay in seconds between chunk analyses to avoid rate limits
